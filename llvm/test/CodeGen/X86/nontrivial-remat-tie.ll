; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py UTC_ARGS: --version 2
; RUN: llc -mtriple=i686-unknown-unknown -frame-pointer=all -non-trivial-rematerialization=true < %s | FileCheck %s

; Test rematerialization of instructions with tied operands. Most two address
; instructions have tied operands.

define void @test1(i32* %ptr) {
; CHECK-LABEL: test1:
; CHECK:       # %bb.0:
; CHECK-NEXT:    pushl %ebp
; CHECK-NEXT:    .cfi_def_cfa_offset 8
; CHECK-NEXT:    .cfi_offset %ebp, -8
; CHECK-NEXT:    movl %esp, %ebp
; CHECK-NEXT:    .cfi_def_cfa_register %ebp
; CHECK-NEXT:    pushl %ebx
; CHECK-NEXT:    pushl %edi
; CHECK-NEXT:    pushl %esi
; CHECK-NEXT:    .cfi_offset %esi, -20
; CHECK-NEXT:    .cfi_offset %edi, -16
; CHECK-NEXT:    .cfi_offset %ebx, -12
; CHECK-NEXT:    movl 8(%ebp), %eax
; CHECK-NEXT:    movl (%eax), %ecx
; CHECK-NEXT:    movl 28(%eax), %esi
; CHECK-NEXT:    movl %ecx, %edx
; CHECK-NEXT:    notl %edx
; CHECK-NEXT:    movl %edx, 4(%eax)
; CHECK-NEXT:    leal (%ecx,%esi), %edx
; CHECK-NEXT:    movl %edx, 4(%eax)
; CHECK-NEXT:    movl 8(%eax), %ebx
; CHECK-NEXT:    addl %ecx, %ebx
; CHECK-NEXT:    movl %esi, %edx
; CHECK-NEXT:    subl %ebx, %edx
; CHECK-NEXT:    movl %edx, 8(%eax)
; CHECK-NEXT:    movl 48(%eax), %ebx
; CHECK-NEXT:    movl 52(%eax), %edi
; CHECK-NEXT:    movl %edi, 52(%eax)
; CHECK-NEXT:    movl %ebx, 48(%eax)
; CHECK-NEXT:    movl %edx, 8(%eax)
; CHECK-NEXT:    movl %ecx, %edx
; CHECK-NEXT:    notl %edx
; CHECK-NEXT:    movl %edx, 8(%eax)
; CHECK-NEXT:    movl %ecx, 16(%eax)
; CHECK-NEXT:    movl %esi, 20(%eax)
; CHECK-NEXT:    leal (%ecx,%esi), %edx
; CHECK-NEXT:    movl %edx, 12(%eax)
; CHECK-NEXT:    movl %edx, 20(%eax)
; CHECK-NEXT:    movl %esi, 12(%eax)
; CHECK-NEXT:    movl %ecx, 16(%eax)
; CHECK-NEXT:    popl %esi
; CHECK-NEXT:    popl %edi
; CHECK-NEXT:    popl %ebx
; CHECK-NEXT:    popl %ebp
; CHECK-NEXT:    .cfi_def_cfa %esp, 4
; CHECK-NEXT:    retl
  %p0 = getelementptr i32, i32* %ptr, i32 7
  %v2 = load i32, i32* %p0, align 4
  %v1 = load i32, i32* %ptr, align 4

  %n  = xor i32 %v1, -1
  %p1 = getelementptr i32, i32* %ptr, i32 1
  store volatile i32 %n, i32* %p1, align 4
  %v3 = add i32 %v1, %v2
  store volatile i32 %v3, i32* %p1, align 4

  %p2 = getelementptr i32, i32* %ptr, i32 2
  %v4 = load volatile i32, i32* %p2, align 4
  %v5 = add i32 %v1, %v4
  %v6 = sub i32 %v2, %v5
  store volatile i32 %v6, i32* %p2, align 4

  %p64 = getelementptr i64, i64* %ptr, i32 6
  %v7  = load volatile i64, i64* %p64, align 4
  store volatile i64 %v7, i64* %p64, align 8

  store volatile i32 %v6, i32* %p2, align 4
  store volatile i32 %n, i32* %p2, align 4

  %p4 = getelementptr i32, i32* %ptr, i32 4
  store volatile i32 %v1, i32* %p4, align 4
  %p5 = getelementptr i32, i32* %ptr, i32 5
  store volatile i32 %v2, i32* %p5, align 4

  %p3 = getelementptr i32, i32* %ptr, i32 3
  store volatile i32 %v3, i32* %p3, align 4
  store volatile i32 %v3, i32* %p5, align 4
  store volatile i32 %v2, i32* %p3, align 4
  store volatile i32 %v1, i32* %p4, align 4

  ret void
}
